{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5abe1e",
   "metadata": {},
   "source": [
    "# Hackathon Challenge: Predicting Restaurant Annual Turnover\n",
    "\n",
    "This notebook outlines the process of building a machine learning model to predict the annual turnover of restaurants across India based on various features provided in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd98c46",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b5d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3274/2529261010.py:21: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['Opening Day of Restaurant'] = pd.to_datetime(df['Opening Day of Restaurant'], errors='coerce')\n",
      "/tmp/ipykernel_3274/2529261010.py:21: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df['Opening Day of Restaurant'] = pd.to_datetime(df['Opening Day of Restaurant'], errors='coerce')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m\n\u001b[1;32m     44\u001b[0m numerical_transformer \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     45\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     46\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolynomial\u001b[39m\u001b[38;5;124m'\u001b[39m, PolynomialFeatures(degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, include_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[1;32m     47\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler())\n\u001b[1;32m     48\u001b[0m ])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Update the pipeline to use an advanced model tuning strategy\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m model \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mpreprocessor\u001b[49m),\n\u001b[1;32m     52\u001b[0m                         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m))])\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# New hyperparameter search space for RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m     55\u001b[0m param_distributions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__num_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m200\u001b[39m),\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__reg_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[1;32m     63\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load the Datasets\n",
    "train_df = pd.read_csv('../data/Train_dataset_(1).csv')\n",
    "test_df = pd.read_csv('../data/Test_dataset_(1).csv')\n",
    "\n",
    "# Feature Engineering Function\n",
    "def feature_engineering(df):\n",
    "    # Existing feature engineering steps\n",
    "    df['Opening Day of Restaurant'] = pd.to_datetime(df['Opening Day of Restaurant'], errors='coerce')\n",
    "    df['Restaurant Age'] = (datetime.now() - df['Opening Day of Restaurant']).dt.days / 365\n",
    "    df.drop('Opening Day of Restaurant', axis=1, inplace=True)\n",
    "    df['Cuisine Count'] = df['Cuisine'].apply(lambda x: len(x.split(',')))\n",
    "    df.drop('Cuisine', axis=1, inplace=True)\n",
    "    ratings_columns = ['Overall Restaurant Rating', 'Live Music Rating', 'Comedy Gigs Rating', \n",
    "                       'Value Deals Rating', 'Live Sports Rating']\n",
    "    df[ratings_columns] = SimpleImputer(strategy='median').fit_transform(df[ratings_columns])\n",
    "    \n",
    "    # New feature engineering steps\n",
    "    # Example: Interaction between 'Facebook Popularity Quotient' and 'Instagram Popularity Quotient'\n",
    "    df['Social Media Popularity'] = df['Facebook Popularity Quotient'] * df['Instagram Popularity Quotient']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = feature_engineering(train_df)\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "X = train_df.drop(['Annual Turnover', 'Registration Number'], axis=1)\n",
    "y = train_df['Annual Turnover']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Update preprocessing for numerical data to include polynomial features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('polynomial', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Update the pipeline to use an advanced model tuning strategy\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('model', lgb.LGBMRegressor(objective='regression'))])\n",
    "\n",
    "# New hyperparameter search space for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'model__num_leaves': np.arange(20, 200),\n",
    "    'model__max_depth': [-1, 5, 10, 15, 20],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "    'model__n_estimators': np.arange(100, 1000, 100),\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'model__reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'model__reg_lambda': [0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Using RandomizedSearchCV for model tuning\n",
    "random_search = RandomizedSearchCV(model, param_distributions, n_iter=50, cv=3, scoring='neg_root_mean_squared_error', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "model = random_search.best_estimator_\n",
    "\n",
    "# Prediction and RMSE Calculation\n",
    "val_predictions = model.predict(X_val)\n",
    "rmse_val = sqrt(mean_squared_error(y_val, val_predictions))\n",
    "print(f\"Validation RMSE: {rmse_val}\")\n",
    "\n",
    "# Predictions for test dataset\n",
    "test_predictions = model.predict(test_df.drop(['Registration Number'], axis=1))\n",
    "\n",
    "# Generate and save submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'Registration Number': test_df['Registration Number'],\n",
    "    'Annual Turnover': test_predictions\n",
    "})\n",
    "submission_path = '../data/submission_advanced.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
